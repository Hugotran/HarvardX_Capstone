---
title: "HarvardX: PH125.9x Data Science \n MovieLens_Predicing Ratings Project"
author: "Tran Phu Hoa"
date: "March 25, 2019"
output: 
  pdf_document: 
    number_sections: yes
    toc: yes
---

# Introduction

The main purpose of writing this report is to apply what I have learnt about Data Science in eight previous courses of HarvardX to solve the first challenge of its final course Data Science: "Capstone". 

The report is expected to replicate a full process of a Data Scientist doing a project, and it will adapt part of the structure which is recommended by Dr. Roger D.Peng in his book called "Report Writing for Data Science in R". Thus, those steps are.

1. Defining the question
2. Defining the ideal dataset
4. Obtaining the data
5. Cleaning the data
6. Exploratory data analysis
7. Statistical prediction/modelling
8. Interpretation of results
9. Challenging of results
10. Synthesis and write up
11. Creating reproducible code


# Defining the question

The main goal is to find out a model that can make the best prediction for the scores rated by users for different movies. The Root Mean Square Error (RMSE) will be used to evaluate how well models perform.  Models have the lowest RMSE will rank in first place as the best predicting model.


# Defining the ideal dataset

Dataset will be the 10M version of the [MovieLens dataset](https://grouplens.org/datasets/movielens/10m/). In order to obtain this dataset, the project will apply codes provided by the course as below.


```{r Obtaining the dataset, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}

#############################################################
# Create edx set, validation set, and submission file
#############################################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", 
                                         repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", 
                                     repos = "http://cran.us.r-project.org")

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- read.table(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                      col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)

colnames(movies) <- c("movieId", "title", "genres")

movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

```

In addition, the course gives codes to make validation sets as below.


```{r Create validation sets, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
# Validation set will be 10% of MovieLens data

set.seed(1)
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set

validation <- temp %>% 
     semi_join(edx, by = "movieId") %>%
     semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set

removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)
```

The "edx" subset will be the main dataset for this analysis and modelling, while the "validation" subset will be used to calculate RMSE for final algorithm.

Save the dataset to the local system, so that it saves the loading times for further analysis.

```{r Save "edx.RData and "validation.RData, echo = FALSE}

save(edx, file = "edx.RData")

save(validation, file = "validation.RData")
```



\pagebreak

# Exploring the "edx" dataset

Loading useful packages

```{r, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
if(!require(tidyverse)) install.packages("tidyverse", 
                                         repos = "http://cran.us.r-project.org")

if(!require(lubridate)) install.packages("lubridate", 
                                         repos = "http://cran.us.r-project.org")

```


Take a look at the dataset using "glimpse" function in "tidyverse" package, and it shows that the "edx" dataset has 9,000,055 observations and 6 variables. There are three types of data including integer, double and character. In fact, "userId" and "timestamp" are coded in integer, "movieId" and "rating" are double, and "title" and "genres" are character. 

```{r Take a look at the dataset, echo = FALSE}

glimpse(edx)

```


Look for NA as the missing value in the dataset using "summary" function. The result indicates that there is no missing value in the "edx" dataset.

```{r Find missing values in the dataset, echo = FALSE}

summary(edx)

```


There are about 70,000 unique users, and 797 groups of genres. The rates are continuous variables, however, they would be classified as categorical variables with 10 different scores. The number of distinct movie is expected to be the same with the number of titles, however it seems that two movies had the same name. 

```{r , echo = FALSE}

edx %>% summarize(n_users = n_distinct(userId),
                  n_movies = n_distinct(movieId),
                  n_rating = n_distinct(rating),
                  n_title = n_distinct(title),
                  n_genres = n_distinct(genres),
                  n_timestamp = n_distinct(timestamp))
```


The dataset does not seem to be in the tidy format. The first reason is more than one variables are included in the same column, for example "Boomerang (1992)" can be divided into two columns which are "Movie title" and "Released year". Furthemore, the column "timestamp" looks meaningless, and it should be transformed to date format. In "genres" column, instead of clumping those genres together, it may be better to separate them.

The following activities will tidy up the "edx" dataset.

```{r Transform "timestamp" to date variable using "lubridate" package, echo = FALSE}

# Separate variables in "genres", and put them into "genres" column gain
tidy_edx_sep_genres <- edx %>% separate_rows(genres, sep = "\\|")

# Parse date to "timestamp" variable
tidy_edx_date <- tidy_edx_sep_genres %>% 
  mutate(date_of_rating = as_datetime(timestamp)) %>%
  select(c("userId", "movieId", "rating", "title", "genres", "date_of_rating"))

```

```{r Separate "title" column into "title" and "movie_year", echo = TRUE}

#Select object "year" in the "title" column, and create "movie_year" variable
tidy_edx <- tidy_edx_date %>% 
  mutate(movie_year = str_extract(tidy_edx_date$title, regex("\\(\\d{4}\\)"))) 

#Detect "year" in the title column
tidy_edx <- tidy_edx %>%
  mutate(movie_year = str_extract(tidy_edx$movie_year, regex("\\d{4}")))

```

```{r Change the type of "movie_year" and "movieId" to integer, echo = TRUE}

tidy_edx <- tidy_edx %>%
  mutate(movie_year = as.integer(movie_year), movieId = as.integer(movieId))

```


Save tidy_edx to the local system.

```{r Save "tidy_edx", echo = FALSE}

save(tidy_edx, file = "tidy_edx.RData")

```


Remove unnecessary dataset "tidy_edx_date", "tidy_edx_sep_genres"

```{r}

rm("tidy_edx_date", "tidy_edx_sep_genres")

gc()
```

```{r}

glimpse(tidy_edx)

```


```{r Summary of Tidy_edx dataset, echo = FALSE}

summary(tidy_edx)

```


There are about 20 different genres and 90 unique released years for 10,676 movie titles.

```{r Count the number of unique data in each variable, echo = FALSE}

tidy_edx %>% summarize(n_users = n_distinct(userId),
                  n_movies = n_distinct(movieId),
                  n_rating = n_distinct(rating),
                  n_title = n_distinct(title),
                  n_genres = n_distinct(genres),
                  n_date = n_distinct(date_of_rating),
                  n_movieyear = n_distinct(movie_year))

```


```{r Plot the histogram of "rating" }

tidy_edx %>%
  ggplot(aes(rating)) + 
  geom_histogram(binwidth = 0.05, color = "blue") +
  scale_x_discrete(limits = c(seq(0.5,5,0.5))) + 
  scale_y_continuous(breaks = c(seq(0, 7000000, 500000))) +
  xlab("Ratings") +
  ylab("Number of ratings") + 
  ggtitle("Histogram of ratings")

```


"4.0" score had the highest number of ratings (6,730,401), and "0.5" had the lowest one (215,932).

```{r Calculate the number of rates for each rating, echo = TRUE}

tidy_edx %>% group_by(rating) %>% 
  summarize(n_rating = n()) %>% 
  arrange(desc(n_rating))

```


```{r Summary statistic of "rating", echo = TRUE}

tidy_edx %>% summarize(mean_rating = mean(rating), 
                       median_rating = median(rating), 
                       sd_rating = sd(rating))

```


```{r}

tidy_edx %>% group_by(movieId, title) %>%
  summarize(n_movie = n()) %>% 
  arrange(desc(n_movie))

```


```{r}

tidy_edx %>% ggplot(aes(userId)) +
  geom_histogram(binwidth = 400) +
  labs(x = "userId", y = "count")

```


Compute the number of ratings for each movie and then plot it against the year the movie came out. 
Use the square root transformation on the counts.

```{r}

tidy_edx %>% group_by(movieId) %>%
  summarize(n_ratings = n(), 
            year = as.character(first(movie_year))) %>%
  qplot(year, n_ratings, data = ., geom = "boxplot") +
  coord_trans(y = "sqrt") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 6)) +
  labs(title = "Boxplot of number of ratings and released year of movies", 
       x = "Released year of movies", 
       y = "Number of ratings")

```


```{r}

tidy_edx %>% group_by(movieId) %>%
  summarize(mean_rating = mean(rating),
            year = as.character(first(movie_year))) %>%
  qplot(year, mean_rating, data = ., geom = "boxplot") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 6)) +
  labs(title = "Boxplot of ratings and released year of movies",
       x = "Released year of movies", 
       y = "Ratings")

```


```{r}

tidy_edx %>% mutate(date = round_date(date_of_rating, unit = "quarter")) %>%
  group_by(date) %>%
  summarize(mean_rating = mean(rating), n_rating = n()) %>%
  ggplot(aes(date, mean_rating, size = n_rating)) +
  geom_point(alpha = 0.1) +
  scale_size(name  = "Number of ratings") +
  geom_smooth() + 
  theme_light() +
  labs(title = "Average ratings in quarters of years",
       x = "Year", 
       y = "Average of ratings")

```


"Genres" seems to effect how users rate, for example, "Film-noir" was scored the highest rate (4.2 points) on average. "Horror" movies had smallest score which was about 0.8.

```{r }

tidy_edx %>% group_by(genres) %>% 
  summarize(n_rating = n(), 
            avg_rating = mean(rating), 
            se_rating = sd(rating)) %>%
  filter(n_rating >= 1000) %>% 
  arrange(desc(n_rating)) %>% 
  ggplot (aes(x=genres, y=avg_rating)) +
  geom_point() +
  geom_errorbar(aes(ymin=avg_rating - se_rating, 
                    ymax=avg_rating + se_rating), 
                width=0.4, colour="red", 
                alpha=0.8, size=1.3) +
  geom_bar(stat="identity", fill="skyblue", alpha=0.7) +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

```


```{r Plot the relationship between movies' genres and the average of rating, echo = TRUE}

tidy_edx %>% group_by(genres) %>%
  summarize(n = n(), 
            avg_rating = mean(rating), 
            se = sd(rating)/sqrt(n())) %>%
  filter(n >= 1000) %>% 
  mutate(genres = reorder(genres, avg_rating)) %>%
  ggplot(aes(x = genres, 
             y = avg_rating, 
             ymin = avg_rating - 2*se, 
             ymax = avg_rating + 2*se)) + 
  geom_point() +
  geom_errorbar() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```


I want to see what movies are rating in the highest and the bottom.

```{r}

edx %>% filter(rating == 0.5) %>%
  group_by(title) %>% 
  summarize(n_rating = n()) %>%
  arrange(desc(n_rating))
  
```


Number of movies produced per year

```{r}

tidy_edx %>%
select(movie_year, movieId) %>%
group_by(movie_year) %>%
summarise(count = n_distinct(movieId)) %>%
arrange(desc(count)) %>%
ggplot(aes(x = movie_year, y = count)) +
geom_bar(stat = "identity") +
labs(title = "Movies Production", 
     x = "Released year of movies", 
     y = "Number of movies produced") 

```


What are the most rated movie genres?
Note: This process could take several minutes

```{r}

tidy_edx %>%
group_by(genres) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
ggplot(aes(x = reorder(genres, -count), y = count)) +
geom_bar(stat = "identity") +
scale_y_continuous(breaks = c(seq(0, 7000000, 500000))) +
theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0)) +
labs(title = "Movies by Genres", 
     x = "Movies' genres", 
     y = "Number of ratings")

```


```{r}
tidy_edx %>%
group_by(genres) %>%
summarise(mean_rating = mean(rating)) %>%
arrange(desc(mean_rating)) %>%
ggplot(aes(x = reorder(genres, -mean_rating), y = mean_rating)) +
geom_bar(stat = "identity") +
theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0)) +
labs(title = "Movies by Genres", 
     x = "Movies' genres", 
     y = "Average of ratings")

```

Exploring the affect of number of movies in a single period on average rating of that interval.

```{r}

test <- tidy_edx %>% 
  mutate(date = round_date(date_of_rating, unit = "week")) %>%
  group_by(date) %>% 
  nest() %>% 
  mutate(n_movie = map(data, ~n_distinct(.x$movieId)),
         mean_rating = map(data, ~mean(.x$rating)))

a <- test %>% unnest(n_movie,mean_rating)

a %>% ggplot(aes(date, mean_rating, size = n_movie)) +
  geom_point(alpha = 0.1) +
  scale_size(name  = "Number of movies") +
  geom_smooth() + 
  theme_light()

```

\pagebreak

# Modellling
## RMSE

```{r}
# "Metrics" package will be used to calculate RMSE in this project.
library(Metrics)

# "caret" package will help to create train and test datasets.
library(caret)

```

## Create training data and testing data for machine learning

```{r Create training data and testing data, echo = FALSE}

set.seed(2019)

test_index <- createDataPartition(tidy_edx$rating, time = 1, p = 0.8, list = FALSE)

train_data <- tidy_edx %>% slice(test_index)
test_data <- tidy_edx %>% slice(-test_index)

```


Use semi_join() to ensure that all users and movies in the testing data are also in the training data

```{r ensure that all users and movies in the testing data are also in the training set, echo = FALSE}

test_data <- test_data %>% 
  semi_join(train_data, by = "movieId") %>%
  semi_join(train_data, by = "userId")

```


Save train_data and test_data to the local system as "train_data.RData" and "test_data.RData" respectively

```{r Save train_data and test_data to the local system}

save(train_data, "train_data.RData")
save(test_data, "test_data.RData")

```


## Matrix factorization approach

### Benchmark model

By using the same predited value for all movies and users, this approach expected to be the simplest possible recommendation system. The model will be the baseline for models comparisons.

A model-based approach seems to fix the expectation as its assumption is to predict the same rating for all movies and all users, and those variations in the prediction would be explained by random variables. 

$$ Y_{u, i} = \mu + \epsilon_{u, i} $$

$\mu$ is the true rating for all movies and users.
$\epsilon_{u,i}$ are variations contained everythings the model does not explain, and they are assumed to be identical and independent which are sampled from the same distribution centered at zero. 

The mean of rating is about 3.5 points.

```{r Benchmark model, echo = TRUE}

mean_rating <- mean(train_data$rating)

mean_rating

```


As all rating will be equal to mean of rating ($\mu$), RMSE of this averaging model will be about 1.061.

```{r RMSE of the Bechmark model, echo = TRUE}

benchmark_rmse <- rmse(test_data$rating, mean_rating)

benchmark_rmse

```


This gives the baseline RMSE to compare with next modelling approaches.

In order to do better than simply predicting the average rating, we incorporate some of insights we gained during the exploratory data analysis.

Create table of results to report RMSE values of different models in the project.

```{r Report the RMSE of the Benchmark model to Table of results, echo = TRUE}

RMSE_results <- data_frame(Model = "Benchmark", RMSE = benchmark_rmse)

RMSE_results %>% knitr::kable()

```

### Movie effect model

The Explanatory analysis suggests that some movies were rated higher than the others, and the next model will capture this effect by adding $b_{i}$ term which is the average rating for movie i.

$$Y_{u, i} = \mu +b_{i}+ \epsilon_{u, i}$$
$b_{i}$ is average rating for movie i.
$b_{i}$ can be calculated by using linear regression function like this.

```{r eval=FALSE, include=FALSE}
fit <- lm(rating ~ as.factor(movieId), data = train_data)
```


However, this technique will crash the computer as the dataset is big. In fact, it is more efficient to treat $b_{i}$ as the function of the mean of rating minus the overall mean for each movie.

```{r Calculate b_i, echo = TRUE}

movie_effect_avgs <- train_data %>%
  group_by(movieId) %>%
  summarize(b_i = mean(rating - mean_rating))

```


Draw the histogram of b_i

```{r Plot histogram of b_i, echo = TRUE}

movie_effect_avgs %>% 
  qplot(b_i, 
        geom ="histogram",
        bins = 10, data = .,
        color = I("blue"),
        ylab = "Number of movies",
        main = "Number of movies with the computed b_i")

```

Predicted values of ratings in test_date using Movie effect model

```{r Predicted values of ratings in test_date using Movie effect model, echo = TRUE}

movie_effect_predicted_ratings <- mean_rating + test_data %>%
  left_join(movie_effect_avgs, by = "movieId") %>%
  .$b_i

```


Calculate RMSE of the Movie effect model

```{r RMSE of the Movie effect model, echo = TRUE}

movie_effect_model_rmse <- rmse(movie_effect_predicted_ratings, test_data$rating)

movie_effect_model_rmse

```


```{r Report the RMSE of Movie effect model to Table of results, echo = TRUE}

RMSE_results <- bind_rows(RMSE_results,
                          data_frame(Model = "Movie effect model",  
                                     RMSE = movie_effect_model_rmse))

RMSE_results %>% knitr::kable()

```


### Movie-User effect model

It is observed that each user will rate differently. The graph using the train_data will show this user effect.

Plot the histogram of b_u with users who rated more than 100 times

```{r Plot the histogram of b_u, echo = TRUE}

train_data %>% 
  left_join(movie_effect_avgs, by='movieId') %>%
  group_by(userId) %>%
  filter(n() >= 100) %>%
  summarize(b_u = mean(rating - mean_rating - b_i)) %>%
  qplot(b_u,
        geom ="histogram",
        bins = 30, data = .,
        color = I("black"))

```


The movie-user effect model would be

$$Y_{u, i} = \mu + b_{i} + b_{u} + \epsilon_{u, i}$$
$b_{u}$ is a user effect.

To avoid potential crash using linear regression approach, the movie-user effect model are computed as the sum of overall mean of rating $\mu$, the movie effect $b_{i}$ and the user effect $b_{u}. The $b_{u} are the average of the leftover obtained after removing the overall mean and the movie effect from the ratings $Y_{u, i}.


Calculate b_u

```{r user_effect_avgs, echo = TRUE}

user_effect_avgs <- train_data %>%
  left_join(movie_effect_avgs, by='movieId') %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mean_rating - b_i))
  
```


Predict the rating in test_data using Movie-user effect model

```{r Movie-User effect model, echo = TRUE}

movie_user_effect_predicted_ratings <- test_data %>%
  left_join(movie_effect_avgs, by='movieId') %>%
  left_join(user_effect_avgs, by='userId') %>%
  mutate(pred = mean_rating + b_i + b_u) %>%
  .$pred

```


Calculate RMSE of Movie-user effect model

```{r The RMSE of Movie-User effect model, echo = TRUE}

movie_user_effect_rmse <- rmse(movie_user_effect_predicted_ratings, test_data$rating)
movie_user_effect_rmse

```


Report the RMSE of Movie-User effect model to Table of results

```{r Report the RMSE of Movie-User effect model to Table of results, echo = TRUE}

RMSE_results <- bind_rows(RMSE_results,
                          data_frame(Model = "Movie-User effect model",  
                                     RMSE = movie_user_effect_rmse))

RMSE_results %>% knitr::kable()

```


### Regularized Movie-User effect model

Set up a Lambdas vector 

```{r Set up a Lambdas vector , echo = TRUE}

lambdas <- seq(0, 10, 0.25)

```


Build a function to run Movie-user effect model with different values of lambdas, and calculate their RMSE 

```{r A function to run Movie-User effect model with different lambdas, echo = TRUE}

rmses <- sapply(lambdas, function(l){
  
  mean_rating <- mean(train_data$rating)
  
  b_i <- train_data %>% 
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mean_rating)/(n()+l))
  
  b_u <- train_data %>% 
    left_join(b_i, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - mean_rating)/(n()+l))
  
  movie_user_effect_predicted_ratings <- 
    test_data %>% 
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    mutate(pred = mean_rating + b_i + b_u) %>%
    .$pred
  
  return(rmse(movie_user_effect_predicted_ratings, test_data$rating))
})

```


Visualize the rmse and lambdas to observe the optimal value of lambda 

```{r plot_lambdas, echo = TRUE}

qplot(lambdas, rmses)  

```


The optimal lambda is:

```{r The optimal lambda, echo = TRUE}

lambda <- lambdas[which.min(rmses)]
lambda

```


Report the RMSE of the Movie-User effect model with the optimal lambda

```{r Report the RMSE of the Movie-User effect model with the optimal lambda, echo = TRUE}

RMSE_results <- bind_rows(RMSE_results,
                          data_frame(Model ="Regularized movie-user effect model",  
                                     RMSE = min(rmses)))
RMSE_results %>% knitr::kable()

```


\pagebreak

# Running other approaches

This section will show the steps to conduct four machine learning algorithms. The first one is to run Random forest using "Ranger" package. The second one is k-nearest neighbor approach in the "caret" package. The following approaches are also in the "caret" package including Quantile Regression Neural Network and Bayesian Regularized Neural Networks.

The purpose of doing this is to explore the power of other algorithms in predicting the "rating" variable and learn how to run and tune them to get better results. In fact, the expectation is to know some limitations in those machine learning "blackbox" such as how they use the memory of the computer and how long it takes to get the predicted results.

## Random forest approach using "Ranger" package

### Random forest with 300 trees in subset

```{r}

# Remove and free up working space

rm(list = ls(all.names = TRUE))
gc()
memory.limit()
memory.size()

# Load necessary packages

library(tidyverse)
library(ranger)
library(rsample)
library(tictoc)
library(Metrics)
library(caret)



tic()

load("tidy_edx.RData")
load("tidy_validation.RData")

set.seed(2019)

test_index <- createDataPartition(tidy_edx$rating, time = 1, p = 0.8, list = FALSE)

train_data <- tidy_edx %>% slice(test_index)
test_data <- tidy_edx %>% slice(-test_index)


#Use semi_join() to ensure that all users and movies in the testing data are also in the training data

test_data <- test_data %>% 
  semi_join(train_data, by = "movieId") %>%
  semi_join(train_data, by = "userId")

#Subset the train_data

subset_train_data <- train_data %>%
  group_by(userId) %>% 
  mutate(count = n()) %>%
  filter(count >= 100) %>% 
  ungroup(userId) %>% 
  select(-count)


sample <- sample_n(train_data, 0.001 * nrow(train_data))

rm(tidy_edx)
gc()

#Create validation set
cv_split <- vfold_cv(sample, v = 5) #v: how many times the data should split

#Mapping train & validate
cv_data <- cv_split %>%
  mutate(train = map(splits, ~training(.x)),
         validate = map(splits, ~testing(.x)))

#Tune the Hyper-Parameters
cv_tune <- cv_data %>% crossing(mtry = 1:6)

# Random forest model

cv_models_tunerf <- cv_tune %>%
  mutate(model = map2(train, 
                      mtry, 
                      ~ ranger(formula = 
                                 rating ~.,
                                 data = .x, 
                                 mtry = .y,
                                 num.trees = 300, # the number of trees in the forest
                                 respect.unordered.factors = "order", # set "order" for regression
                                 seed = 42))) # set the seed to get reproducible results

# Generate validate predictions for each model

cv_prep_tunerf <- cv_models_tunerf %>% 
  mutate(validate_actual = map(validate, ~.x$rating),
         validate_predicted = map2(.x = model,
                                   .y = validate,
                                   ~predict(.x, .y)$predictions))

# Calculate validate RMSE for each fold and mtry combination

cv_eval_tunerf <- cv_prep_tunerf %>% 
  mutate(validate_rmse = map2_dbl(.x = validate_actual, 
                                  .y = validate_predicted, 
                                  ~rmse(actual = .x, predicted = .y)))

# Calculate the mean validate_mae for each mtry used  

cv_eval_tunerf %>% 
  group_by(mtry) %>% 
  summarise(mean_rmse = mean(validate_rmse))


toc()
#  mtry mean_rmse
#  <int>     <dbl>
#1     1      1.03
#2     2      1.03
#3     3      1.04
#4     4      1.04
#5     5      1.04
#6     6      1.04

#> toc()
#164.92 sec elapsed

#> memory.size()
#[1] 4852.09
```


### Run random forest with the subset of 300 trees
```{r}

# Remove and free up working space

rm(list = ls(all.names = TRUE))
gc()
memory.limit()
memory.size()

# Load necessary packages

library(tidyverse)
library(ranger)
library(rsample)
library(tictoc)
library(Metrics)
library(caret)



tic()

load("tidy_edx.RData")
load("tidy_validation.RData")

set.seed(2019)

test_index <- createDataPartition(tidy_edx$rating, time = 1, p = 0.8, list = FALSE)

train_data <- tidy_edx %>% slice(test_index)
test_data <- tidy_edx %>% slice(-test_index)


#Use semi_join() to ensure that all users and movies in the testing data are also in the training data

test_data <- test_data %>% 
  semi_join(train_data, by = "movieId") %>%
  semi_join(train_data, by = "userId")

#Subset the train_data

subset_train_data <- train_data %>%
  group_by(userId) %>% 
  mutate(count = n()) %>%
  filter(count >= 100) %>% 
  ungroup(userId) %>% 
  select(-count)


sample <- sample_n(train_data, 0.001 * nrow(train_data))

rm(tidy_edx)
gc()

#Create validation set
cv_split <- vfold_cv(sample, v = 5) #v: how many times the data should split

#Mapping train & validate
cv_data <- cv_split %>%
  mutate(train = map(splits, ~training(.x)),
         validate = map(splits, ~testing(.x)))

#Tune the Hyper-Parameters
cv_tune <- cv_data %>% crossing(mtry = 1:6)

# Random forest model

cv_models_tunerf <- cv_tune %>%
  mutate(model = map2(train, 
                      mtry, 
                      ~ ranger(formula = 
                                 rating ~.,
                               data = .x, 
                               mtry = .y,
                               num.trees = 500, # the number of trees in the forest
                               seed = 42))) # set the seed to get reproducible results

# Generate validate predictions for each model

cv_prep_tunerf <- cv_models_tunerf %>% 
  mutate(validate_actual = map(validate, ~.x$rating),
         validate_predicted = map2(.x = model,
                                   .y = validate,
                                   ~predict(.x, .y)$predictions))

# Calculate validate RMSE for each fold and mtry combination

cv_eval_tunerf <- cv_prep_tunerf %>% 
  mutate(validate_rmse = map2_dbl(.x = validate_actual, 
                                  .y = validate_predicted, 
                                  ~rmse(actual = .x, predicted = .y)))

# Calculate the mean validate_mae for each mtry used  

cv_eval_tunerf %>% 
  group_by(mtry) %>% 
  summarise(mean_rmse = mean(validate_rmse))


toc()

# A tibble: 6 x 2
#   mtry mean_rmse
#  <int>     <dbl>
#1     1      1.02
#2     2      1.03
#3     3      1.03
#4     4      1.04
#5     5      1.04
#6     6      1.04

#> toc()
#440.61 sec elapsed
#memory.size() 
#6737.25
```



```{r}

# Remove and free up working space

rm(list = ls(all.names = TRUE))
gc()
memory.limit()
memory.size()

# Load necessary packages

library(tidyverse)
library(ranger)
library(rsample)
library(tictoc)
library(Metrics)
library(caret)



tic()

load("tidy_edx.RData")
load("tidy_validation.RData")

set.seed(2019)

test_index <- createDataPartition(tidy_edx$rating, time = 1, p = 0.8, list = FALSE)

train_data <- tidy_edx %>% slice(test_index)
test_data <- tidy_edx %>% slice(-test_index)


#Use semi_join() to ensure that all users and movies in the testing data are also in the training data

test_data <- test_data %>% 
  semi_join(train_data, by = "movieId") %>%
  semi_join(train_data, by = "userId")

#Subset the train_data

subset_train_data <- train_data %>% 
  group_by(movieId) %>% 
  mutate(count = n()) %>%
  filter(count >= 1000) %>% 
  ungroup(movieId) %>% 
  select(-count) %>%
  group_by(userId) %>% 
  mutate(count = n()) %>% 
  filter(count >= 100) %>% 
  ungroup(userId) %>% 
  select(-count)


sample <- sample_n(subset_train_data, 0.002 * nrow(subset_train_data))

rm(tidy_edx)
gc()

#Create validation set
cv_split <- vfold_cv(sample, v = 5) #v: how many times the data should split

#Mapping train & validate
cv_data <- cv_split %>%
  mutate(train = map(splits, ~training(.x)),
         validate = map(splits, ~testing(.x)))

#Tune the Hyper-Parameters
cv_tune <- cv_data %>% crossing(mtry = 1:6)

cv_models_tunerf <- cv_tune %>%
  mutate(model = map2(train, 
                      mtry, 
                      ~ ranger(formula = rating ~.,
                                            data = .x, 
                                            mtry = .y, 
                                            num.trees = 300,
                                            seed = 42)))

# Generate validate predictions for each model
cv_prep_tunerf <- cv_models_tunerf %>% 
  mutate(validate_actual = map(validate, ~.x$rating),
         validate_predicted = map2(.x = model, 
                                   .y = validate, 
                                   ~predict(.x, .y)$predictions))

# Calculate validate RMSE for each fold and mtry combination
cv_eval_tunerf <- cv_prep_tunerf %>% 
  mutate(validate_rmse = map2_dbl(.x = validate_actual, 
                                  .y = validate_predicted, 
                                  ~rmse(actual = .x, predicted = .y)))

# Calculate the mean validate_mae for each mtry used  
cv_eval_tunerf %>% 
  group_by(mtry) %>% 
  summarise(mean_rmse = mean(validate_rmse))


toc()

#   mtry mean_rmse
#  <int>     <dbl>
#1     1     1.000
#2     2     1.00 
#3     3     1.00 
#4     4     1.01 
#5     5     1.01 
#6     6     1.01 

#> toc()
#458.72 sec elapsed
```




```{r}

# Remove and free up working space

rm(list = ls(all.names = TRUE))
gc()
memory.limit()
memory.size()

# Load necessary packages

library(tidyverse)
library(ranger)
library(rsample)
library(tictoc)
library(Metrics)
library(caret)



tic()

load("tidy_edx.RData")
load("tidy_validation.RData")

set.seed(2019)

test_index <- createDataPartition(tidy_edx$rating, time = 1, p = 0.8, list = FALSE)

train_data <- tidy_edx %>% slice(test_index)
test_data <- tidy_edx %>% slice(-test_index)


# Use semi_join() to ensure that all users and movies in the testing data are also in the training data

test_data <- test_data %>% 
  semi_join(train_data, by = "movieId") %>%
  semi_join(train_data, by = "userId")

# Subset the train_data

subset_tidy_edx <- tidy_edx %>% 
  group_by(movieId) %>% 
  mutate(count = n()) %>%
  filter(count >= 1000) %>% 
  ungroup(movieId) %>% 
  select(-count)
 
test_index <- createDataPartition(subset_tidy_edx$rating, time = 1, p = 0.001, list = FALSE)

sample <- subset_tidy_edx %>% slice(test_index)


#Create validation set
cv_split <- vfold_cv(sample, v = 5) #v: how many times the data should split

#Mapping train & validate
cv_data <- cv_split %>%
  mutate(train = map(splits, ~training(.x)),
         validate = map(splits, ~testing(.x)))

#Tune the Hyper-Parameters
cv_tune <- cv_data %>% crossing(mtry = 1:6)

cv_models_tunerf <- cv_tune %>%
  mutate(model = map2(train, mtry, ~ ranger(formula = rating ~.,
                                            data = .x,
                                            mtry = .y,
                                            num.trees = 300,
                                            seed = 42)))

# Generate validate predictions for each model
cv_prep_tunerf <- cv_models_tunerf %>% 
  mutate(validate_actual = map(validate, ~.x$rating),
         validate_predicted = map2(.x = model, .y = validate, ~predict(.x, .y)$predictions))

# Calculate validate RMSE for each fold and mtry combination
cv_eval_tunerf <- cv_prep_tunerf %>% 
  mutate(validate_rmse = map2_dbl(.x = validate_actual, .y = validate_predicted, ~rmse(actual = .x, predicted = .y)))

# Calculate the mean validate_mae for each mtry used  
cv_eval_tunerf %>% 
  group_by(mtry) %>% 
  summarise(mean_rmse = mean(validate_rmse))

#   mtry mean_rmse
#  <int>     <dbl>
#1     1      1.01
#2     2      1.02
#3     3      1.02
#4     4      1.02
#5     5      1.02
#6     6      1.02

#> toc()
#235.86 sec elapsed
#memory.size()
#[1] 6780.84
toc()

```


## k-Nearest Neighbors approach 


```{r}

# Remove and free up working space

rm(list = ls(all.names = TRUE))
gc()
memory.limit()
memory.size()

# Load necessary packages

library(tidyverse)
library(ranger)
library(rsample)
library(tictoc)
library(Metrics)
library(caret)



tic()

load("tidy_edx.RData")
load("tidy_validation.RData")

set.seed(2019)

test_index <- createDataPartition(tidy_edx$rating, time = 1, p = 0.8, list = FALSE)

train_data <- tidy_edx %>% slice(test_index)
test_data <- tidy_edx %>% slice(-test_index)


#Use semi_join() to ensure that all users and movies in the testing data are also in the training data

test_data <- test_data %>% 
  semi_join(train_data, by = "movieId") %>%
  semi_join(train_data, by = "userId")

#Subset the train_data

subset_train_data <- train_data %>% 
  group_by(movieId) %>% 
  mutate(count = n()) %>%
  filter(count >= 1000) %>% 
  ungroup(movieId) %>% 
  select(-count)
 
test_index <- createDataPartition(subset_train_data$rating, time = 1, p = 0.001, list = FALSE)

sample <- subset_train_data %>% slice(test_index)


fitControl <- trainControl(method = "cv",
                           number = 5,
                           p = 0.8)


model_knn <- train(rating ~ movieId + userId + genres + date_of_rating,
           data = sample,
           method = "knn",
           trControl = fitControl,
           verbose= FALSE)

actual_rating <- test_data$rating

predict_rating <- predict(model_knn, test_data)

rmse(actual_rating, predict_rating)


toc()
#1.100068
#2127.06 sec elapsed
#memory.size()
#[1] 6257.54
```


## Quantile Regression Neural Network with caret


```{r}

# Remove and free up working space

rm(list = ls(all.names = TRUE))
gc()
memory.limit()
memory.size()

# Load necessary packages

library(tidyverse)
library(ranger)
library(rsample)
library(tictoc)
library(Metrics)
library(caret)



tic()

load("tidy_edx.RData")
load("tidy_validation.RData")

set.seed(2019)

test_index <- createDataPartition(tidy_edx$rating, time = 1, p = 0.8, list = FALSE)

train_data <- tidy_edx %>% slice(test_index)
test_data <- tidy_edx %>% slice(-test_index)


#Use semi_join() to ensure that all users and movies in the testing data are also in the training data

test_data <- test_data %>% 
  semi_join(train_data, by = "movieId") %>%
  semi_join(train_data, by = "userId")

#Subset the train_data

subset_train_data <- train_data %>% 
  group_by(userId) %>% 
  mutate(count = n()) %>%
  filter(count >= 100) %>% 
  ungroup(userId) %>% 
  select(-count)
 

sample <- sample_n(subset_train_data, 0.0001 * nrow(train_data))

rm(tidy_edx)
gc()

# set up 10-fold cross validation procedure
train_control <- trainControl(
  method = "cv", 
  number = 5)

# train model
model_qrnn <- train(rating ~ movieId + userId + date_of_rating + genres + movie_year,
                  data = sample,
                  method = "qrnn",
                  trControl = train_control
)



actual_rating <- test_data$rating

predict_rating <- predict(model_qrnn, test_data)

rmse(actual_rating, predict_rating)
#1.07381

#946.59 sec elapsed

toc()

```


## Bayesian Regularized Neural Networks


```{r}

# Remove and free up working space

rm(list = ls(all.names = TRUE))
gc()
memory.limit()
memory.size()

# Load necessary packages

library(tidyverse)
library(ranger)
library(rsample)
library(tictoc)
library(Metrics)
library(caret)



tic()

load("tidy_edx.RData")
load("tidy_validation.RData")

set.seed(2019)

test_index <- createDataPartition(tidy_edx$rating, time = 1, p = 0.8, list = FALSE)

train_data <- tidy_edx %>% slice(test_index)
test_data <- tidy_edx %>% slice(-test_index)


#Use semi_join() to ensure that all users and movies in the testing data are also in the training data

test_data <- test_data %>% 
  semi_join(train_data, by = "movieId") %>%
  semi_join(train_data, by = "userId")

#Subset the train_data

subset_train_data <- train_data %>% 
  group_by(movieId) %>% 
  mutate(count = n()) %>%
  filter(count >= 1000) %>% 
  ungroup(movieId) %>% 
  select(-count)
 
test_index <- createDataPartition(subset_train_data$rating, time = 1, p = 0.001, list = FALSE)

sample <- subset_train_data %>% slice(test_index)


fitControl <- trainControl(method = "cv",
                           number = 5,
                           p = 0.8)


model_brnn <- train(rating ~ movieId + userId + genres + date_of_rating,
           data = sample,
           method = "brnn",
           trControl = fitControl,
           verbose= FALSE)

actual_rating <- test_data$rating

predict_rating <- predict(model_brnn, test_data)

rmse(actual_rating, predict_rating)


toc()
#1.046815
#133.58 sec elapsed
#> memory.size()
#[1] 4100.72
```


```{r}
# Remove and free up working space

rm(list = ls(all.names = TRUE))
gc()
memory.limit()
memory.size()

# Load necessary packages

library(tidyverse)
library(ranger)
library(rsample)
library(tictoc)
library(Metrics)
library(caret)



tic()

load("tidy_edx.RData")
load("tidy_validation.RData")

set.seed(2019)

test_index <- createDataPartition(tidy_edx$rating, time = 1, p = 0.8, list = FALSE)

train_data <- tidy_edx %>% slice(test_index)
test_data <- tidy_edx %>% slice(-test_index)


#Use semi_join() to ensure that all users and movies in the testing data are also in the training data

test_data <- test_data %>% 
  semi_join(train_data, by = "movieId") %>%
  semi_join(train_data, by = "userId")

#Subset the train_data

subset_train_data <- train_data %>% 
  group_by(userId) %>% 
  mutate(count = n()) %>%
  filter(count >= 100) %>% 
  ungroup(userId) %>% 
  select(-count)
 

sample <- sample_n(subset_train_data, 0.0001 * nrow(train_data))

rm(tidy_edx)
gc()

# set up 10-fold cross validation procedure

train_control <- trainControl(
  method = "cv", 
  number = 5
)

# train model
model_brnn <- train(rating ~ movieId + userId + date_of_rating + genres + movie_year,
                  data = sample,
                  method = "brnn",
                  trControl = train_control
)



actual_rating <- test_data$rating

predict_rating <- predict(model_brnn, test_data)

rmse(actual_rating, predict_rating)
#1.048848
#96.31 sec elapsed
#> memory.size()
#[1] 6175.41
toc()

```

# Validate the models
## Remove and free up working space

```{r Remove and free up working space, echo = FALSE}

rm(list = ls(all.names = TRUE))
gc()
memory.limit()
memory.size()

```

## Load necessary packages

```{r Necessary packages, echo = FALSE}

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")

```

## Load "validation" dataset

```{r}
load("validation.RData")
```

## Tidy up the "validation" dataset.

```{r Transform "timestamp" to date variable using "lubridate" package, echo = FALSE}

#Separate variables in "genres", and put them into "genres" column gain
validation_sep_genres <- validation %>% separate_rows(genres, sep = "\\|")

#Parse date to "timestamp" variable
validation_date <- validation_sep_genres %>% mutate(date_of_rating = as_datetime(timestamp)) %>%
  select(c("userId", "movieId", "rating", "title", "genres", "date_of_rating"))

```


```{r Separate "title" column into "title" and "movie_year", echo = FALSE}

#Select object "year" in the "title" column, and create "movie_year" variable
#Detect "year" in the title column
tidy_validation <- validation_date %>% 
  mutate(movie_year = str_extract(validation_date$title, regex("\\(\\d{4}\\)"))) 

tidy_validation <- tidy_validation %>%
  mutate(movie_year = str_extract(tidy_validation$movie_year, regex("\\d{4}")))

```


```{r}

tidy_validation <- tidy_validation %>%
  mutate(movie_year = as.integer(movie_year), movieId = as.integer(movieId))

```


Save tidy_edx to the local system.

```{r Save "tidy_validation", echo = FALSE}

save(tidy_validation, file = "tidy_validation.RData")

```


Remove unnecessary dataset "tidy_edx_date", "tidy_edx_sep_genres"

```{r}
rm("validation_date", "validation_sep_genres")

gc()
```


## Validate three best models that have the lowest RMSEs

```{r Regularized Movie-User effect model, echo = TRUE}

mean_rating <- mean(tidy_edx$rating)
  
b_i <- tidy_edx %>% 
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mean_rating)/(n()+lambda))
  
b_u <- tidy_edx %>% 
    left_join(b_i, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - mean_rating)/(n()+lambda))
  
movie_user_effect_predicted_ratings <- 
    tidy_validation %>% 
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    mutate(pred = mean_rating + b_i + b_u) %>%
    .$pred

movie_user_effect_rmse <- rmse(movie_user_effect_predicted_ratings, tidy_validation$rating)
movie_user_effect_rmse

```

```{r}
# Remove and free up working space

rm(list = ls(all.names = TRUE))
gc()
memory.limit()
memory.size()

# Load necessary packages

library(tidyverse)
library(ranger)
library(tictoc)
library(Metrics)
library(caret)

tic()

load("tidy_edx.RData")


set.seed(2019)

test_index <- createDataPartition(tidy_edx$rating, time = 1, p = 0.1, list = FALSE)

subset_tidy_edx <- tidy_edx %>% slice(test_index)

model_ranger <- ranger(formula = rating ~.,
                       data = subset_tidy_edx,
                       mtry = 1,
                       num.trees = 300,
                       seed = 42)

rm(tidy_edx, test_index, subset_tidy_edx)
load("tidy_validation.RData")

actual_rating <- tidy_validation$rating
predict_rating <- predict(model_ranger, tidy_validation)$predictions
rmse_model_ranger <- rmse(predict_rating, actual_rating)
#0.9939
toc()
```

## Conclusion
Factorization approach, K-means neighboor, Random forest and neural a"Regularized Movie-User effect" model 

The limitations are:
The machine capacity
The understanding of algorithms to tune
The understanding of packages

